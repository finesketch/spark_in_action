{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==2.4.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (2.4.5)\n",
      "Requirement already satisfied: py4j==0.10.7 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from pyspark==2.4.5) (0.10.7)\n",
      "Apache Spark session created.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
    "\n",
    "if ('sc' in locals() or 'sc' in globals()):\n",
    "    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n",
    "\n",
    "!pip install pyspark==2.4.5\n",
    "\n",
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')\n",
    "    \n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Apache Spark session created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (lit,col,concat,split)\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(\"\")\n",
    "\n",
    "relative_path1 = \"../03 The majestic role of the dataframe/data/Restaurants_in_Wake_County_NC.csv\"\n",
    "absolute_file_path1 = os.path.join(current_dir, relative_path1)\n",
    "\n",
    "relative_path2 = \"../03 The majestic role of the dataframe/data/Restaurants_in_Durham_County_NC.json\"\n",
    "absolute_file_path2 = os.path.join(current_dir, relative_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(path=absolute_file_path1,header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.json(absolute_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeRestaurantsDf = util.build_wake_restaurants_dataframe(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "durhamRestaurantsDf = util.build_durham_restaurants_dataframe(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+-------------------+-----------------+------------+-----------+------+-------+------------------+\n",
      "| datasetId|                name|            address1|address2|       city|state|       zip|           tel|          dateStart|             type|        geoX|       geoY|county|dateEnd|                id|\n",
      "+----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+-------------------+-----------------+------------+-----------+------+-------+------------------+\n",
      "|4092016024|                WABA|2502 1/2 HILLSBOR...|    null|    RALEIGH|   NC|     27607|(919) 833-1710|2011-10-18 00:00:00|       Restaurant|-78.66818477|35.78783803|  Wake|   null|NC_Wake_4092016024|\n",
      "|4092021693|  WALMART DELI #2247|2010 KILDAIRE FAR...|    null|       CARY|   NC|     27518|(919) 852-6651|2011-11-08 00:00:00|       Food Stand|-78.78211173|35.73717591|  Wake|   null|NC_Wake_4092021693|\n",
      "|4092017012|CAROLINA SUSHI &a...|5951-107 POYNER V...|    null|    RALEIGH|   NC|     27616|(919) 981-5835|2015-08-28 00:00:00|       Restaurant|-78.57030208|35.86511564|  Wake|   null|NC_Wake_4092017012|\n",
      "|4092030288|THE CORNER VENEZU...|    7500 RAMBLE WAY |    null|    RALEIGH|   NC|     27616|          null|2015-09-04 00:00:00|Mobile Food Units|  -78.537511|35.87630712|  Wake|   null|NC_Wake_4092030288|\n",
      "|4092015530|        SUBWAY #3726| 12233 CAPITAL BLVD |    null|WAKE FOREST|   NC|27587-6200|(919) 556-8266|2009-12-11 00:00:00|       Restaurant|-78.54097555|35.98087357|  Wake|   null|NC_Wake_4092015530|\n",
      "+----------+--------------------+--------------------+--------+-----------+-----+----------+--------------+-------------------+-----------------+------------+-----------+------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- datasetId: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address1: string (nullable = true)\n",
      " |-- address2: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: string (nullable = true)\n",
      " |-- tel: string (nullable = true)\n",
      " |-- dateStart: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- geoX: double (nullable = true)\n",
      " |-- geoY: double (nullable = true)\n",
      " |-- county: string (nullable = false)\n",
      " |-- dateEnd: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "util.combineDataframes(wakeRestaurantsDf, durhamRestaurantsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
